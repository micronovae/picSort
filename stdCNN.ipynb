{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getList(file_path):\n",
    "    \n",
    "    print('getList is ok')\n",
    "    \n",
    "    DataToPros = os.listdir(file_path+'/')\n",
    "    \n",
    "    return DataToPros\n",
    "\n",
    "def getFile(file_path,file_list):\n",
    "    \n",
    "    print('getFile is ok')\n",
    "    \n",
    "    data = []\n",
    "    label = []\n",
    "    for i in file_list:\n",
    "        data.append(file_path+'/'+i)\n",
    "        if file_path == 'pics_modal/rumor_pics':\n",
    "            label.append(0)\n",
    "        else:\n",
    "            label.append(1)\n",
    "            \n",
    "    return data,label\n",
    "\n",
    "def proList():\n",
    "    \n",
    "    print('proList is ok')\n",
    "\n",
    "    file_path_rumor = \"pics_modal/rumor_pics\"\n",
    "    file_path_truth = \"pics_modal/truth_pics\"\n",
    "    list_rumor = getList(file_path_rumor)\n",
    "    list_truth = getList(file_path_truth)\n",
    "    \n",
    "    rd,rl = getFile(file_path_rumor,list_rumor[:20])\n",
    "    td,tl = getFile(file_path_truth,list_truth[:20])\n",
    "    \n",
    "    prodata = rd+td\n",
    "    prolabel = rl+tl\n",
    "    \n",
    "    temp = np.array([prodata,prolabel])\n",
    "    temp = temp.T\n",
    "    np.random.shuffle(temp)\n",
    "    \n",
    "    prodata = list((temp[:,0]))\n",
    "    prolabel = list((temp[:,1]))\n",
    "    prolabel = [int(float(i)) for i in prolabel]\n",
    "\n",
    "    return prodata, prolabel\n",
    "    \n",
    "\n",
    "def getBat(data_list,label_list,width,height,batSize,capacity):\n",
    "    \n",
    "    print('getBat is ok')\n",
    "\n",
    "    image = []\n",
    "    \n",
    "    for i in data_list:\n",
    "        \n",
    "        temp = tf.read_file(str(i))\n",
    "        temp = tf.image.decode_jpeg(temp,channels = 3)\n",
    "        temp = tf.image.resize_image_with_crop_or_pad(temp,\n",
    "                                                       width,height)\n",
    "    \n",
    "        temp = tf.image.per_image_standardization(temp)\n",
    "        image.append(temp)\n",
    "        \n",
    "    label = tf.cast(label_list,tf.int32)\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    return image,label\n",
    "#     image_batch,label_batch = tf.train.batch([image,label_list],\n",
    "#             batch_size = batSize,\n",
    "#             num_threads = 1,\n",
    "#             capacity = capacity)\n",
    "#     images_batch = tf.cast(image_batch,tf.float32)\n",
    "#     labels_batch = tf.reshape(label_batch,[batSize])\n",
    "    \n",
    "#     return images_batch,label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    res = tf.Variable(tf.random_normal(shape,stddev = 0.01))\n",
    "    return res\n",
    "\n",
    "def norm(x,lsize = 4):\n",
    "    return tf.nn.lrn(x,depth_radius = lsize,bias = 1,\n",
    "                      alpha = 0.001/9.0,beta = 0.75)\n",
    "\n",
    "def conv2d(x, w, b):\n",
    "    x = tf.nn.conv2d(x,w,strides = [1,1,1,1],padding = \"SAME\")\n",
    "    x = tf.nn.bias_add(x,b)\n",
    "    return tf.nn.relu(x)    \n",
    "    # tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)\n",
    "    # x(input)  : [batch, in_height, in_width, in_channels]\n",
    "    # W(filter) : [filter_height, filter_width, in_channels, out_channels]\n",
    "    # strides   : The stride of the sliding window for each dimension of input.\n",
    "    #             For the most common case of the same horizontal and vertices strides, \n",
    "    #             strides = [1, stride, stride, 1]\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize = [1, 2, 2, 1],\n",
    "                          strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    # tf.nn.max_pool(value, ksize, strides, padding, data_format='NHWC', name=None)\n",
    "    # x(value)              : [batch, height, width, channels]\n",
    "    # ksize(pool大小)        : A list of ints that has length >= 4. \n",
    "    #     The size of the window for each dimension of the input tensor.\n",
    "    # strides(pool滑动大小)   : A list of ints that has length >= 4. \n",
    "    #   The stride of the sliding window for each dimension of the input tensor.\n",
    "\n",
    "def loss(logits,label_batches):\n",
    "    \n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                                    labels=label_batches)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    return loss\n",
    " \n",
    "def get_accuracy(logits,labels):\n",
    "    \n",
    "    acc = tf.nn.in_top_k(logits,labels,1)\n",
    "    acc = tf.cast(acc,tf.float32)\n",
    "    acc = tf.reduce_mean(acc)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mmodel(data):\n",
    "\n",
    "    # init w      \n",
    "    weights = {\n",
    "      \"w1\":init_weights([3,3,3,16]),\n",
    "      \"w2\":init_weights([3,3,16,128]),\n",
    "      \"w3\":init_weights([3,3,128,256]),\n",
    "      \"w4\":init_weights([4096,4096]),\n",
    "      \"wo\":init_weights([4096,2])}\n",
    "     \n",
    "    # init biases\n",
    "    biases = {\n",
    "     \"b1\":init_weights([16]),\n",
    "     \"b2\":init_weights([128]),\n",
    "     \"b3\":init_weights([256]),\n",
    "     \"b4\":init_weights([4096]),\n",
    "     \"bo\":init_weights([2])\n",
    "     }\n",
    "\n",
    "\n",
    "    layer1 = conv2d(data,weights[\"w1\"],biases[\"b1\"])\n",
    "    layer2 = max_pool_2x2(layer1)\n",
    "    layer2 = tf.nn.lrn(layer2)\n",
    "    layer3 = conv2d(layer2,weights[\"w2\"],biases[\"b2\"])\n",
    "    layer4 = max_pool_2x2(layer3)\n",
    "    layer4 = tf.nn.lrn(layer4)\n",
    "    layer5 = conv2d(layer4,weights[\"w3\"],biases[\"b3\"])\n",
    "    layer6 = max_pool_2x2(layer5)\n",
    "    layer6 = tf.reshape(layer6,[-1,weights[\"w4\"].get_shape().as_list()[0]])\n",
    "    layer7 = tf.nn.relu(tf.matmul(layer6,weights[\"w4\"])+biases[\"b4\"])\n",
    "    softmax = tf.add(tf.matmul(layer7,weights[\"wo\"]),biases[\"bo\"])\n",
    "    \n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(loss,lr):\n",
    "    train_op = tf.train.RMSPropOptimizer(lr,0.9).minimize(loss)\n",
    "    return train_op\n",
    "\n",
    "def cnn_run(data_bat,label_bat):\n",
    "    log_dir = '/Users/yanghang/Desktop/Dataset/picSort/'\n",
    "    p = mmodel(data_bat)\n",
    "    cost = loss(p,label_bat)\n",
    "    train_op = training(cost,0.01)\n",
    "    acc = get_accuracy(p,label_bat)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver()\n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(sess = sess,coord = coord)\n",
    "\n",
    "    try:\n",
    "        for step in np.arange(20):\n",
    "            print(step)\n",
    "#             if coord.should_stop():\n",
    "#                 break\n",
    "            _,train_acc,train_loss = sess.run([train_op,acc,cost])\n",
    "            print(\"loss:{} accuracy:{}\".format(train_loss,train_acc))\n",
    "            if step % 100 == 0:\n",
    "                check = os.path.join(log_dir,\"model.ckpt\")\n",
    "                saver.save(sess,check,global_step = step)\n",
    "                \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Wrong!!!')\n",
    "        \n",
    "#     finally:\n",
    "#         coord.request_stop()\n",
    "#     coord.join(threads)\n",
    "    sess.close()\n",
    "        \n",
    "    \n",
    "def main():\n",
    "    \n",
    "    data, label = proList()\n",
    "    data_bat, label_bat = getBat(data,label,32,32,5,64)\n",
    "    cnn_run(data_bat,label_bat)\n",
    "\n",
    "if __name__ == 'main':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proList is ok\n",
      "getList is ok\n",
      "getList is ok\n",
      "getFile is ok\n",
      "getFile is ok\n",
      "getBat is ok\n",
      "0\n",
      "loss:0.6933293342590332 accuracy:0.5\n",
      "1\n",
      "loss:0.6933252215385437 accuracy:0.5\n",
      "2\n",
      "loss:0.6933209300041199 accuracy:0.5\n",
      "3\n",
      "loss:0.6933164596557617 accuracy:0.5\n",
      "4\n",
      "loss:0.6933118104934692 accuracy:0.5\n",
      "5\n",
      "loss:0.6933070421218872 accuracy:0.5\n",
      "6\n",
      "loss:0.6933020353317261 accuracy:0.5\n",
      "7\n",
      "loss:0.6932969093322754 accuracy:0.5\n",
      "8\n",
      "loss:0.6932915449142456 accuracy:0.5\n",
      "9\n",
      "loss:0.6932859420776367 accuracy:0.5\n",
      "10\n",
      "loss:0.6932801008224487 accuracy:0.5\n",
      "11\n",
      "loss:0.6932740211486816 accuracy:0.5\n",
      "12\n",
      "loss:0.6932677030563354 accuracy:0.5\n",
      "13\n",
      "loss:0.6932612061500549 accuracy:0.5\n",
      "14\n",
      "loss:0.6932546496391296 accuracy:0.5\n",
      "15\n",
      "loss:0.6932479739189148 accuracy:0.5\n",
      "16\n",
      "loss:0.6932411193847656 accuracy:0.5\n",
      "17\n",
      "loss:0.6932340264320374 accuracy:0.5\n",
      "18\n",
      "loss:0.6932266354560852 accuracy:0.5\n",
      "19\n",
      "loss:0.6932187080383301 accuracy:0.5\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
